{% extends "page.twig" %}

{% block content %}

    <p xmlns="http://www.w3.org/1999/html">To express textual variance, CollateX uses a graph-based data model
        (<a href="http://dx.doi.org/10.1016/j.ijhcs.2009.02.001" title="Schmidt, D. and Colomb, R, 2009. A data structure for representing multi-version texts online, International Journal of Human-Computer Studies, 67.6, 497-514.">Schmidt 2009</a>).
        On top of this model it supports several algorithms to progressively align multiple text versions.</p>


    <h2 id="gothenburg-model">The Gothenburg Model</h2>

    <p>Developers of CollateX and
        <a href="#bib-juxta-2013">Juxta</a> met for the first time in&nbsp;2009 at a joint workshop of
        <a href="http://www.cost-a32.eu/">COST Action&nbsp;32</a> and
        <a href="http://www.interedition.eu/">Interedition</a> in Gothenburg. They started discussing, how the different concerns
        of computer-supported collation of texts could be separated such that these two as well as similar projects would have a common
        understanding of its process and could thus collaborate more efficiently on the development of collation tools
        as well as their components. As a first result of this ongoing discussion, the participants identified five distinct tasks
        present in any computer-supported collation workflow.</p>

    <p>CollateX is designed around this separation of concerns.</p>

    <h3 id="tokenization">Tokenization</h3>

    <div class="figure float-right">
        <img src="/images/tokenizer.png" alt="Tokenizer">
        <p class="caption">A tokenized text</p>
    </div>

    <p>While computers can compare a text's versions on a character-by-character basis, in the more common use case each
        version is first split up into parts &ndash; henceforth called <em>tokens</em> &ndash; so the comparison can be conducted
        on a more coarse-grained level where the tokens to be compared ideally correspond to the text's units which carry meaning.
        This pre-processing step is called <strong>tokenization</strong> and performed by a <em>tokenizer</em>; it can happen on any
        level of granularity, i.e. on the level of syllables, words, lines, phrases, verses, paragraphs or text nodes in a
        <a href="http://en.wikipedia.org/wiki/Document_Object_Model" title="Wikipedia Article">DOM</a>.</p>

    <p>Another service provided by tokenizers and of special value to the comparison of natural language texts relates to marked-up
        text versions: As most collation software primarily compares text versions based on their textual content, embedded markup
        would usually get in the way of this process and therefore needs to be discarded or “pushed in the background”, so the
        collation tool does not have to be concerned about the specifics of a text's encoding. At the same time it might be valuable
        to keep the markup context of every token for reference, for instance if one wanted to make use of it when comparing tokens.</p>

    <p>The figure to the right depicts this process: The line on top shows a marked-up text, its content as the
        characters "a", "b", "c" and "d" &ndash; each representing a token &ndash; and "e1", "e2" as examples of embedded markup elements.
        A markup-aware tokenizer would not only split this version into 4 distinct tokens but transform it into a sequence of such tokens,
        with each token referring to its markup context.</p>

    <p>For now CollateX offers a simple tokenizer, mainly serving prototyping purposes by either</p>

    <ul>
    <li>splitting plain text without any embedded markup on boundaries determined by
        <a href="http://en.wikipedia.org/wiki/Whitespace_character" title="Wikipedia Article">whitespace</a>, or</li>
    <li>evaluating a configurable <a href="http://www.w3.org/TR/xpath/" title="XPath 1.0 W3C Spec">XPath 1.0 expression</a> on an XML-encoded
        text version which yields a list of node values as textual tokens.</li>
    </ul>

    <p>While not offering a comprehensive tokenizer itself, CollateX can be combined with any such tool that suits your specific requirements.
        CollateX only expects you then to provide text versions in pre-tokenized form and define a <strong>token comparator function</strong> which &ndash; when
        called with any two tokens &ndash; evaluates to a <em>match</em> in case those two tokens shall  be treated as equal, or a <em>mismatch</em> in case
        this should not be assumed. Formally speaking, a token comparator function defines an
        <a href="http://en.wikipedia.org/wiki/Equivalence_relation" title="Wikipedia Article">equivalence relation</a> over all tokens for a
        collation. In processing tokens on the level of their equivalence defined by such a relation, CollateX is agnostic with regard to what constitutes
        a token in your specific use case, whether it is plain text, text with a markup context or not textual at all.</p>

    <p>Detailed information about when and how to define your own notion of a token and its corresponding equivalence relation will be given in
        the following sections on CollateX' usage. Its built-in tokenizer will provide for an easy start. Later on you can opt for a more versatile tokenizer
        and/or token comparator function in order to enhance the accuracy of collation results.</p>

    <h3 id="normalization">Normalization/Regularization</h3>

    <p>With a configurable equivalence relation between tokens (defined via the aforementioned comparator function), CollateX can compare
        text versions which are comprised of arbitrary tokens sequences. For a larger number of use cases though, this flexibility of defining a
        fully customized comparator function is not really needed. It might suffice to normalize the tokens' textual content
        such that an exact matching of the normalized content yields the desired equivalence relation. For instance, in many cases all tokens
        of the text versions are normalized to their lower-case equivalent before being compared, thereby making their comparison case insensitive. Other
        examples would be the removal of punctuation, the rule-based normalization of orthographic differences or the
        <a href="http://en.wikipedia.org/wiki/Stemming" title="Wikipedia Article">stemming of words</a>.</p>

    <p>Just as with the tokenizer included in CollateX, its normalization options are rather simple. Beyond the mentioned case normalization
        and the removal of punctuation and/or whitespace characters, CollateX does not include any sophisticated normalization routines. Instead its
        API and supported input formats provide the user with options to plug in their own components when needed.</p>

    <h3 id="alignment">Alignment</h3>

    <div class="figure float-right">
        <img src="/images/aligner.png" alt="Alignment">
        <p class="caption">An alignment of 3 versions</p>
    </div>

    <p>After each version has been split into a sequence of tokens and each has been (optionally) normalized, the token
        sequences will be aligned. The alignment process constitutes the core of CollateX' functionality and is generally conducted
        by <ol>
        <li>finding a set of matching tokens determined by the token equivalence relation, and</li>
        <li>aligning them via the insertion of <em>gaps</em> such that the token sequences of all versions line up optimally.</li>
    </ol></p>

    <p>Looking at an example, assume that we have three versions: the first is comprised of the token sequence ["a", "b",
        "c", "d"], the second reads ["a", "c", "d", "b"] and the third ["b", "c", "d"]. A collation tool may align these three
        versions as depicted on the right. Each version occupies a column, matching tokens are aligned horizontally in a
        row, gaps are inserted as needed during the alignment process and denoted via a hyphen. Depending from
        which perspective one interprets this <strong>alignment table</strong>, one can say that the "b" in the second
        row was <em>omitted</em> in the second version or that it has been <em>added</em> in the first and the third. A
        similar statement can be made about the "b" in the last row, inverting the relationship of being <em>added</em> or
        <em>omitted</em>. Basic edit operations (e.g. those underlying the concept
        of <a href="http://en.wikipedia.org/wiki/Edit_distance" title="Wikipedia Article">edit distance</a>) are thus
        implicitly expressed in such an alignment and can be interpreted accordingly to make assumptions about how a
        text has been changed.
    </p>

    <p>The concept of sequence alignment and its tabular representation is well established in the field of Humanities
        Computing; alignment tables like the one shown can be encoded with well-known apparatus encoding schemes. In
        the parallel segmentation mode of <a href="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/TC.html" title="TEI-P5 Guidelines">TEI-P5's
        apparatus encoding scheme</a>, to pick just one possible representation, each row would be encoded as a segment, with empty readings
        standing in for the gaps. Optionally, consecutive segments with matching readings for each version could be concatenated, so that for our example
        a possible encoding capturing the alignment information reads:
    </p>

    <pre class="prettyprint clear">&lt;app&gt;
  &lt;rdg wit="#w1 #w2"&gt;a&lt;/rdg&gt;
  &lt;rdg wit="#w3" /&gt;
&lt;/app&gt;
&lt;app&gt;
  &lt;rdg wit="#w1 #w3"&gt;b&lt;/rdg&gt;
  &lt;rdg wit="w2" /&gt;
&lt;/app&gt;
&lt;app&gt;
  &lt;rdg wit="#w1 #w2 #w3"&gt;cd&lt;/rdg&gt;
&lt;/app&gt;
&lt;app&gt;
  &lt;rdg wit="#w2"&gt;b&lt;/rdg&gt;
  &lt;rdg wit="#w1 #w3" /&gt;
&lt;/app&gt;</pre>

    <p>Also beyond the field of Humanities Computing, the technique of <a href="http://en.wikipedia.org/wiki/Sequence_alignment" title="Wikipedia Article">sequence alignment</a>
        has many application areas; Bioinformatics for example has addressed it as a computational problem thoroughly in recent years.
        In this context and as part of the larger field of <a href="http://en.wikipedia.org/wiki/Pattern_matching" title="Wikipedia Article">pattern matching</a>,
        extensive research exists on the topic. CollateX primarily strives to make the results of this research available to
        textual scholars. For this import of computational methods it has to be noted though that &ndash; generally speaking &ndash;
        the assessment of findings in the Humanities is based on interpretation. While it certainly can be supported by computational means,
        it is not necessarily computable. As a concrete consequence of that difference in methodology, CollateX
        offers its users not one algorithm optimized by specific criteria, but a choice between
        several <a href="#alignment-algorithms" title="Section">alignment algorithms</a> so they can select the one that
        supports their expected results best, always assuming that any computational heuristic may fail in the light of
        subjective judgement.
    </p>

    <h3 id="analysis-feedback">Analysis/Feedback</h3>

    <div class="figure float-right">
        <img src="/images/analyzer.png" alt="Alignment Analysis">
        <p class="caption">Analyzing an alignment</p>
    </div>

    <p>As the heuristic approach to the problem of sequence alignment may not yield the desired result, a further analysis
        of the alignment may be necessary. Echoing the example from the above section, evidence not accessible to the
        collation tool (e.g. because it was not encoded in the text versions at hand) might support the assumption of token "b"
        in row&nbsp;2 and&nbsp;5 as not only being <em>added</em>/<em>omitted</em> but <em>transposed</em>/<em>moved</em> (see figure to the right).
        While heuristic algorithms may compute transpositions as part of the alignment process, the correctness of such a computation,
        given external evidence and its heuristic nature, obviously cannot be ensured.</p>

    <p>An additional (possibly manual) analysis of the alignment result therefore may alleviate that deficiency by introducing the
        possibility of a feedback cycle, in which users edit the alignment and feed their knowledge back into the alignment process for
        another run delivering enhanced results. The declaration of pre-determined alignments between specific tokens and the
        parametrization of optimizing algorithms along the requirements of a specific use case would be such feedback information which
        influences results substantially.</p>

    <p>CollateX offers rudimentary support for tailoring alignment results to a user's specific requirements, mainly through
        its <a href="#javadoc" title="Section">Java API</a>. It is an area in need for improvement, particularly with regard to its
        ease of use.</p>

    <h3 id="visualization">Visualization</h3>

    <p>The final concern of any collation workflow relates to the visualization of its results. As the broad variety
        of building principles, layouts and notational conventions found in printed apparatuses already suggests, representing
        textual variance is a complex problem on its own. Software like <a href="http://juxtasoftware.org/" title="Homepage">Juxta</a>
        has demonstrated the potential of digital media to cope with this complexity in innovative ways. For CollateX, the visualization
        of results is deemed out of scope at the moment. Instead it provides several <a href="#output">output formats</a> which facilitate
        the integration with software in charge of visualizing results, be it in printed or in digital form.</p>

    <h2 id="variant-graphs" class="clear">The Data Model: Variant Graphs</h2>

    <p>The tabular representation of collation results as shown in the section on <a href="#alignment">sequence aligment</a> is popular,
        in the Humanties and beyond. CollateX can output results in this representation but uses a different one internally
        for modelling textual variance: <strong>variant graphs</strong>.</p>

    <p>Variant graphs are the central data structure of CollateX. Any generated <a href="#output">output</a> from CollateX is a derivation, providing different views on it.
        The idea of a graph-oriented model for expressing textual variance has been originally developed by Desmond Schmidt (<a href="#bib-schmidt-2008" class="citation" title="Reference">Schmidt 2008</a>,
        <a href="#bib-schmidt-2009" class="citation" title="Reference">Schmidt 2009</a>, <a href="#bib-schmidt-2009a" class="citation" title="Reference">Schmidt 2009a</a>)
        and proved to be particularly well suited as a data model for computer-supported collation. The following figure taken from one of his publications
        illustrates it:</p>

    <div class="figure" style="margin-bottom: 1em">
        <img src="/images/variant-graph-schmidt.png" alt="Schmidt's Variant Graph Model">
        <p class="caption">Schmidt/Colomb's Variant Graph Model</p>
    </div>

    <p>Variant graphs are in principal <a href="http://en.wikipedia.org/wiki/Directed_acyclic_graph">directed and acyclic</a>. They are comprised at least of a
        start and end node/vertex ("s" and "e" in the figure above) and can be traversed from the one to the other via labelled edges. The labels on each edge
        contain content segments of compared text versions and a set of identifiers/sigils, denoting the versions which contain the respective content of an edge's label.
        Thus
        <ol>
            <li>common segments of multiple text versions can be <em>merged</em> in a variant graph,</li>
            <li>differing segments result in the graph <em>branching</em> at nodes, while</li>
            <li>each version can still be retrieved from the graph by traversing it along the edges labeled with the appropriate identifier of that version.</li>
        </ol></p>

    <p></p>

    <p>Following these principles, the depicted variant graph models three text versions A, B and C with the following content (markup omitted):</p>

    <table>
        <tr><th>A</th><td>Queste è l'ultima traccia d'un antico acquedotto di sguardi, una orbita assorta e magica:</td></tr>
        <tr><th>B</th><td>Queste è l'ultima cenno d'un antico acquedotto di sguardi, la sua curva sacra e muta:</td></tr>
        <tr><th>C</th><td>Queste è l'ultima porta d'un antico acquedotto di sguardi, la sua curva sacra e solitaria:</td></tr>
    </table>

    <p>In order to account for the <a href="#gothenburg-model">separation of concerns</a> laid out above, CollateX' implementation of Schmidt's model
        adjusted the latter slightly. Instead of labelling the edges of a variant graph with two attributes &ndash; the content as well as the sigils of text versions containing it &ndash;
        the edges of variant graphs in CollateX are only labeled with sigil sets. The version's content segments &ndash; in the form of partial token sequences &ndash; have
        been moved to the nodes/vertices. The ending of the example graph then looks like this (with sigils being mapped from A, B, C to W1, W2, W3):</p>

    <div class="figure" style="margin-bottom: 1em">
        <img src="/images/variant-graph-collatex.png" alt="CollateX's Variant Graph Model">
        <p class="caption">CollateX' Variant Graph Model</p>
    </div>

    <p>The above illustration does not reveal the internal structure of the graph completely insofar as the nodes' labels in this figure are a simplification.
        For instance, the second node in the graph (read from left to right) is labeled "sacra", with the two versions W2 and W3 "sharing some content". More precisely
        though and in line with the above definition of <a href="#tokenization">tokens and their equivalence relation</a>, W2 and W3 do not "share some content". Instead they
        both contain a token with the content "sacra", both deemed to be equal according to the definition of a specific token comparator function. In the graphical
        representation of the variant graph above, this subtle distinction is not made and both tokens are just represented via their common textual content. In CollateX'
        data model though, this distinction is still relevant and represented: Each node/vertex in a variant graph is not modelled via textual content (as it would be the
        case when translated directly from Schmidt's model) but as a <strong>set of tokens per node</strong> originating from one or more versions, with all tokens in such a
        set belonging to the same equivalence class.</p>

    <p>The described change to Schmidt's model serves mainly two purposes: Firstly, it allows for arbitrary tokens to be compared and their commonalities, differences as
        well as their sequential order to be represented in a graph structure. Secondly, CollateX' graph model is easy to transform into the tabular representation
        introduced further above by ranking the graph's nodes in <a href="http://en.wikipedia.org/wiki/Topological_sorting" title="Wikipedia Article">topological order</a>
        and aligning tokens which belong to nodes of the same rank.</p>

    <p>It has to be noted that also in this data model, the <strong>transposition</strong> of tokens still remains a problematic case. Like in Schmidt's model, CollateX represents the
        transposition of a token (or more precisely: it's content) as a link between nodes (in the case of Schmidt' model: edges) containing the transposed segment. The link is undirected
        and does not form part of a variant graph's traversal scheme because transposition links would break the assertion of a variant graph's acyclic nature and
        consequently the ability to sort it topologically. While the linking of nodes can represent transposed segments sufficiently, it is superimposed
        on a variant graph, i.e. it does not integrate well with it. Future work in this area may yield a more concise representation.</p>

    <h2 id="alignment-algorithms">Alignment Algorithms</h2>

    <p>CollateX strives for maximum flexibility on the users' side when comparing text versions and adjusting the results to their requirements. One part of this
        flexibility is rooted in the support of several alignment algorithms users can switch between and experiment with.</p>

    <p>Currently three algorithms have been implemented. They all operate on variant graph structures and belong to the group of <strong>progressive alignment algorithms</strong>.
        Instead of comparing all versions at once, they <ol>
        <li>start by comparing two versions, </li>
        <li>transforming the result into a variant graph, then</li>
        <li>progressively comparing another versions against that graph, and</li>
        <li>merging the result of that comparison into the graph,</li>
        <li>repeating the procedure until all versions have been merged.</li>
    </ol></p>

    <p>On the one hand, the progressive approach is advantageous because it reduces the problem of comparing an arbitrary number of versions to the
        simpler comparison of a single version with a variant graph representing several ones. The disadvantage on the other hand is the occasional <strong>dependence of
        the result on the order</strong> in which versions are merged into the graph (<a href="#bib-spencer-2004" class="citation" title="Reference">Spencer 2004</a>).
        Adding tools to deal with this dependency, e.g. by performing a <a href="http://en.wikipedia.org/wiki/Computational_phylogenetics" title="Wikipedia Article">phylogenetic analysis</a>
        to determine an optimal order, is planned for a future version.</p>

    <h3 id="dekker-algorithm">Dekker</h3>

    <p>The most mature algorithm offered by CollateX thus far has been developed by Ronald Haentjens Dekker (<a href="#bib-dekker-2011" class="citation" title="Reference">Dekker 2011</a>).
        It aligns an arbitary number of text versions, optimizes the local alignment of partial tokens sequences (phrases) and detects transpositions.</p>

    <h3 id="needleman-wunsch-algorithm">Needleman-Wunsch</h3>

    <p>The <a href="http://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm" title="Wikipedia Article">Needleman-Wunsch algorithm</a>
        (<a href="#bib-needleman-1970" classs="citation" title="Reference">Needleman 1970</a>) is a well-known global alignment
        algorithm broadly applied in Bioinformatics and the social sciences. Based on <a href="http://en.wikipedia.org/wiki/Dynamic_programming" title="Wikipedia Article">dynamic programming</a>,
        this algorithm searches for an optimal alignment of an arbitrary number of versions by consulting a scoring function which penalizes the insertion of gaps. It does not take
        the possibility of transposed segments into account though.</p>

    <p>The scoring function in CollateX' implementation can not be freely configured at the moment; the gap penality is assumed to be constant and equals
        the score of a match.</p>

    <h3 id="medite-algorithm">MEDITE</h3>

    <p>Only recently added to the code base, this algorithm takes its name from a <a href="http://www-poleia.lip6.fr/~ganascia/Medite_Project" title="Homepage">pairwise
        alignment algorithm</a> developed by Julien Bourdaillet and Jean-Gabriel Ganascia (<a href="#bib-bourdaillet-2007" class="citation" title="Reference">Bourdaillet 2007</a>).
        It is based on <a href="http://en.wikipedia.org/wiki/Suffix_tree" title="Wikipedia Article">suffix trees</a> for the search of maximal unique matches between
        text versions and the <a href="http://en.wikipedia.org/wiki/A*_search_algorithm" title="Wikipedia Article">A* algorithm</a> for optimizing the alignment.
        Like Dekker's algorithm, it takes transpositions into account while doing so.</p>

    <p>CollateX' implementation of this algorithm is in an experimental stage. While it already delivers promising results, it has not been
        fully optimized and &ndash; above all &ndash; not been extensively tested. In the case of issues with this algorithm,
        <a href="/about/" title="Contact">the CollateX team</a> would appreciate feedback. Alternatively users can download
        <a href="http://www-poleia.lip6.fr/~ganascia/Medite_Project" title="Homepage">the original version of MEDITE</a> written by the algorithm's
        authors.</p>

    <h2 id="input">Input</h2>

    <p>This section describes the different input formats CollateX supports. Besides the contents of a text's versions to be compared, the
        input may also include parameters like the alignment algorithm to be used.</p>

    <h3 id="text-input">Plain Text</h3>

    <p>Like any collation tool, CollateX can process text versions provided as plain text. As CollateX is written for the Java Virtual Machine,
        internally the comparison of plain text is based on the JVM's string type and thus on 16-bit
        <a href="http://en.wikipedia.org/wiki/Unicode" title="Wikipedia Article">Unicode</a> characters.</p>

    <p>Depending on the way CollateX is used, plain text version can also be provided in <a href="http://docs.oracle.com/javase/7/docs/technotes/guides/intl/encoding.doc.html" title="Java Documentation">other
        encodings supported by the Java Platform</a> and will be converted to Unicode before comparison. The <a href="#cli" title="Section">command line interface</a>
        is one such interface which supports character set conversions.</p>

    <p>Plain text version are always subject to tokenization and optional normalization of the resulting token sequence before they will be compared with each other.</p>

    <h3 id="json-input">JSON</h3>

    <p>As a more flexible format, CollateX supports input in <a href="http://json.org/" title="Website">JavaScript Object Notation (JSON)</a>. A set of text versions
        to be compared can be JSON encoded as follows:</p>

	<pre class="prettyprint">{
  "witnesses" : [
    {
      "id" : "A",
      "content" : "A black cat in a black basket"
    },
    {
      "id" : "B",
      "content" : "A black cat in a black basket"
    },
    {
      "id" : "C",
      "content" : "A striped cat in a black basket"
    },
    {
      "id" : "D",
      "content" : "A striped cat in a white basket"
    }
  ]
}</pre>

    <p>JSON input always consists of a single root object wrapping input data. The root object has one required property containing the versions to be compared which
        (for historical reasons) is named <em>witnesses</em>. The value of this property is of an array (a list) of objects in turn, with each object representing a version.
        The order of the objects in the array determines the order in which they are processed by an alignment algorithms, i.e. merged into a variant graph.</p>

    <p>Each object in the <em>witnesses</em> array must have a unique identifier in the required property <em>id</em>. This identifier will be used in the
        <a href="#output" title="Section">output</a> to reference a particular version. Besides the identifier each object must describe the content of the version.
        The content can either be specified as a string property named <em>content</em> as shown above. In this case the version is treated like a plain text version
        with tokenization and normalization taking place before the alignment.</p>

    <p>Another option is to provide the content of versions in tokenized (and optionally normalized) form:</p>

	<pre class="prettyprint">{
  "witnesses" : [
    {
      "id" : "A",
      "tokens" : [
          { "t" : "A", "ref" : 123 },
          { "t" : "black" : "adj" : true },
          { "t" : "cat", "id" : "xyz" }
      ]
    },
    {
      "id" : "B",
      "tokens" : [
          { "t" : "A" },
          { "t" : "white" : "adj" : true },
          { "t" : "kitten.", "n" : "cat" }
      ]
    }
  ]
}</pre>

    <p>Instead of providing a property <em>content</em> for a version, one can provide a sequence of tokens via the property <em>tokens</em>.
        The version's property value must be a list with one object per token Each token object in turn must at least contain a property <em>t</em>, which defines
        its content. Accordingly, in the example above, version "A" has the tokens ["A", "black", "cat"] whereas version "B" is comprised of the token sequence
        ["A", "white", "kitten"].</p>

    <p>Optionally a <a href="#normalization" title="Section">normalized</a> reading of the token can be provided in the property <em>n</em>.
        Again, in the example above, that means the last token of version "B" is normalized from the reading "kitten" to the reading "cat", thus facilitating
        a match of "kitten" with the last token of version "A".</p>

    <p>Apart from these 2&nbsp; defined properties <em>t</em> and <em>n</em>, token objects can contain an arbitrary number of additional properties.
        Additional properties will not be interpreted by the CollateX but just be passed through, reappearing in
        the <a href="#output" title="Section">output</a> unchanged. Properties like <em>ref</em>, <em>adj</em> or <em>id</em> in the example would be such
        additional properties of a token object. Users of the JSON input can make use of this pass-through mode e.g. in order to uniquely identify aligned tokens
        independently of their (possibly non-unique) content.</p>

    <p>When using interfaces like the <a href="#rest-service" title="Section">HTTP service</a> of CollateX, JSON encoded input can contain optional parameters
        controlling the collation process. You can set the alignment algorithm for instance by providing a property <em>algorithm</em> in the root object with
        one of the values "needleman-wunsch", "medite" or "dekker" (the default):</p>

        <pre class="prettyprint">{
  "witnesses": [ … ],
  "algorithm": "needleman-wunsch"
}</pre>

    <p>There is also limited support for customizing the <a href="#tokenization" title="Section">token comparator function</a>. Via JSON, two functions are available:</p>

        <pre class="prettyprint">{
  "witnesses": [ … ],
  "algorithm": "…",
  "tokenComparator": { type: "equality" }
}</pre>

    <p>The default function, which can also be explicitly configured like shown above, tests for exact equality of the normalized token content. An alternative is the use of approximate matching via
        the a <a href="http://en.wikipedia.org/wiki/Levenshtein_distance" title="Wikipedia">Levenshtein/edit distance</a> threshold for matching tokens:</p>

        <pre class="prettyprint">{
  "witnesses": [ … ],
  "tokenComparator": {
    "type": "levenshtein",
    "distance": 2
  }
}</pre>

    <p>For approximate matching, the <em>type</em> property of the token object descring the token comparator function must be assigned the value "levenshtein".
        The optional property <em>distance</em> defines the maximum edit distance between two normalized tokens strings which is still considered to be a match.
        An edit distance of&nbsp;1 is the default.</p>

    <h3 id="xml-input">XML</h3>

    <h2 id="output">Output</h2>

    <h3 id="json-output">JSON</h3>

    <p>The tabular output format, resembling matrices commonly used in <a href="http://en.wikipedia.org/wiki/Sequence_alignment" title="Wikipedia">sequence alignment</a> results, looks as follows (indentation/whitespace added for easier readability):</p>

    <pre class="prettyprint">{
    "rows": 3,
    "columns": 2,
    "sigils": ["A", "B"],
    "table":[
      [
        [ {"t":"A"} ],
        [ {"t":"A"} ]
      ],[
        [ {"t":"black"} ],
        [ {"t":"white"} ]
      ], [
        [ {"t":"cat"} ],
        [ {"t":"kitten.", "n":"cat"} ]
      ]
    ]
}</pre>

    <p>First 3&nbsp;properties: metadata … dimensions of table; <code>rows</code> aka. number of aligned segments; <code>columns</code> aka. number of witnesses;
        <code>sigils</code> contains ordered set of witness identifiers, maps to order of segments in table …</p>

    <p>Each row: matching segments, each colum/cell: the segment of a witness aka. a list of tokens comprising this segment or <code>null</code> in case of a gap …</p>

    <h3 id="tei-p5-output">TEI P5</h3>

    <pre class="prettyprint">&lt;?xml version='1.0' encoding='UTF-8'?&gt;
&lt;cx:apparatus
  xmlns:cx="http://interedition.eu/collatex/ns/1.0"
  xmlns="http://www.tei-c.org/ns/1.0"&gt;
    A
    &lt;app&gt;
      &lt;rdg wit="A"&gt;black&lt;/rdg&gt;
      &lt;rdg wit="B"&gt;white&lt;/rdg&gt;
    &lt;/app&gt;
    &lt;app&gt;
      &lt;rdg wit="A"&gt;cat&lt;/rdg&gt;
      &lt;rdg wit="B"&gt;kitten.&lt;/rdg&gt;
    &lt;/app&gt;
&lt;/cx:apparatus&gt;</pre>


    <h3 id="graphml-output">GraphML</h3>

    <p>The GraphML-formatted output of a variant graph is suitable for import of (possibly larger) graphs in tools
        for complex graph analysis and visualization, e. g. <a href="http://gephi.org/" title="Homepage">Gephi</a>.
        For an example GraphML document, take a look at sample output from the
        <a href="${cp}/collate/console" title="CollateX Console">web console</a>.</p>

    <h3 id="graphviz-dot-output">GraphViz DOT</h3>

    <pre class="prettyprint">digraph G {
  v301 [label = ""];
  v303 [label = "A"];
  v304 [label = "black"];
  v306 [label = "white"];
  v305 [label = "cat"];
  v302 [label = ""];
  v301 -> v303 [label = "A, B"];
  v303 -> v304 [label = "A"];
  v303 -> v306 [label = "B"];
  v304 -> v305 [label = "A"];
  v306 -> v305 [label = "B"];
  v305 -> v302 [label = "A, B"];
}</pre>

    <h2 id="cli">The Command Line Interface</h2>

    <pre class="prettyprint lang-xml">usage: collatex [&lt;options>] &lt;witness_1> &lt;witness_2> [[&lt;witness_3>] ...]
  -a,--algorithm &lt;arg>           progressive alignment algorithm to use
                                 'dekker' (default), 'medite',
                                 'needleman-wunsch'
  -f,--format &lt;arg>              result/output format: 'csv', 'dot',
                                 'graphml', 'tei'
  -h,--help                      print usage instructions (which your are
                                 looking at right now)
  -ie,--input-encoding &lt;arg>     charset to use for decoding non-XML
                                 witnesses; default: UTF-8
  -o,--output &lt;arg>              output file; '-' for standard output
                                 (default)
  -oe,--output-encoding &lt;arg>    charset to use for encoding the output;
                                 default: UTF-8
  -s,--script &lt;arg>              ECMA/JavaScript resource with functions to be
                                 plugged into the alignment algorithm
  -t,--tokenized                 consecutive matches of tokens will *not* be
                                 joined to segments
  -xml,--xml-mode                witnesses are treated as XML documents
  -xp,--xpath &lt;arg>              XPath 1.0 expression evaluating to tokens of
                                 XML witnesses; default: '//text()'</pre>

    <h3 id="cli-js-callbacks">ECMA/JavaScript Callbacks</h3>

    <h2 id="rest-service">The RESTful Web Service</h2>

    <p>
        This page documents the
        <a href="http://en.wikipedia.org/wiki/Application_programming_interface" title="Wikipedia Page">Application Programming Interface (API)</a>
        of CollateX via which you can provide textual versions (&ldquo;witnesses&rdquo;) to be compared and get the collation result back in a number of formats.
    </p>

    <p>
        The CollateX service is callable via
        <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html" title="RFC">HTTP POST requests</a> to
        <a href="${cp}/collate" title="REST-API Endpoint">${cp}/collate</a>.</p>

    <p>It expects <strong>input</strong> formatted in <a href="http://json.org/" title="Website">JavaScript Object Notation (JSON)</a> as the request body;
        accordingly the content type of the HTTP request must be set to <code>application/json</code> by the client.</p>

    <p>
        The output format of the collator, contained in the response to an HTTP POST request, can be chosen via
        an <code>Accept</code> HTTP header in the request. The following output formats are supported:
    </p>

    <table>
        <tr>
            <th>application/json</th>
            <td><em>(per default)</em> the tabular alignment of the witnesses' tokens, represented in JSON</td>
        </tr>
        <tr>
            <th>application/tei+xml</th>
            <td>the collation result as a list of critical apparatus entries, encoded in <a href="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/TC.html" title="TEI website">TEI P5 parallel segmentation mode</a></td>
        </tr>
        <tr>
            <th>application/graphml+xml</th>
            <td>the variant graph, represented in <a href="http://graphml.graphdrawing.org/">GraphML format</a></td>
        </tr>
        <tr>
            <th>text/plain</th>
            <td>the variant graph, represented in <a href="http://www.graphviz.org/doc/info/lang.html" title="Graphviz' DOT Language Specification">Graphviz' DOT Language</a></td>
        </tr>
        <tr>
            <th>image/svg+xml</th>
            <td>the variant graph, rendered as an <a href="http://www.w3.org/Graphics/SVG/" title="W3C SVG Homepage">SVG</a> vector graphics document</td>
        </tr>
    </table>

    <p>For further examples, take a look at sample output from the
        <a href="${cp}/collate/console" title="CollateX Console">web console</a>.</p>

        <div id="js-apidocs">
            <h2>The HTTP-based JavaScript API</h2>

            <p>Enables the use of CollateX' RESTful API via JavaScript … Based on <a href="http://yuilibrary.com/" title="Homepage">YUI framework</a> …</p>

            <h3>Requirements</h3>

            <p>Add dependencies to header … YUI library plus CollateX module …</p>

        <pre class="prettyprint">&lt;script type="text/javascript" src="http://yui.yahooapis.com/3.8.1/build/yui/yui-min.js">&lt;/script>
&lt;script type="text/javascript" src="http://collatex.net/demo/collatex.js">&lt;/script>
</pre>

            <p>Substitute URL prefix <code>[ROOT]</code> with the base URL of your installation, e.g.
                <a href="${cp}/" title="Base URL">this one</a> for the installation you are currently looking at …</p>

            <p>YUI module <code>interedition-collate</code> available now … supports cross-domain AJAX requests via
                <a href="http://en.wikipedia.org/wiki/Cross-Origin_Resource_Sharing" title="Wikipedia">CORS</a> …</p>

            <h3>Sample usage</h3>

        <pre class="prettyprint">YUI().use("node", "collatex", function(Y) {
    new Y.CollateX({ serviceUrl: "http://collatex.net/demo/collate" }).toTable([{
        id: "A",
        content: "Hello World"
    }, {
        id: "B",
        tokens: [
            { "t": "Hallo", "n": "hello" },
            { "t": "Welt", "n": "world" }
        ]
    }], Y.one("#result"));
});</pre>

            <p>… <code>toTable()</code> takes witness array as first parameter; second parameter is DOM node which serves as container for
                the resulting HTML alignment table …</p>

            <p>… generic <code>collate(witnesses, callback)</code> as well as methods for other formats available:
                <code>toSVG()</code>, <code>toTEI()</code>, <code>toGraphViz()</code> …</p>

            <p>… configuration of a collator instance via methods like <code>withDekker()</code>, <code>withFuzzyMatching(maxDistance)</code> …</p>
        </div>

    <h2 id="javadoc">API Documentation (Javadoc)</h2>

    <p><a href="/apidocs/" title="CollateX API (Javadoc)">here</a></p>

    <h2 id="bibliography">Resources/ Bibliography</h2>

    <dl class="bibliography">
        <dt id="bib-bourdaillet-2007"><a href="http://www-poleia.lip6.fr/~ganascia/Medite_Project?action=AttachFile&do=view&target=LATA+2007" title="Electronic Resource">Bourdaillet 2007</a></dt>
        <dd>Bourdaillet J. and Ganascia J.-G., 2007. Practical block sequence alignment with moves.
            LATA 2007 - International Conference on Language and Automata Theory and Applications, 3/2007.</dd>

        <dt id="bib-collate-2000"><a href="http://www.sd-editions.com/about/index.html" title="Homepage">Collate</a></dt>
        <dd>Robinson, P., 2000. Collate.</dd>

        <dt id="bib-dekker-2011"><a href="http://crdo.up.univ-aix.fr/SLDRdata/doc/show/copenhagen/SDH-2011/proceedings.html" title="Conference Proceedings">Dekker 2011</a></dt>
        <dd>Dekker, R. H. and Middell, G., 2011. Computer-Supported Collation with CollateX: Managing Textual Variance in an Environment with Varying Requirements.
            Supporting Digital Humanities 2011. University of Copenhagen, Denmark. 17-18 November 2011.</dd>

        <dt id="bib-juxta-2013"><a href="https://github.com/performant-software" title="GitHub">Juxta 2013</a></dt>
        <dd>Performant Software Solutions LLC, 2013. Juxta.</dd>

        <dt id="bib-needleman-1970"><a href="http://dx.doi.org/10.1016%2F0022-2836%2870%2990057-4" title="Electronic Resource">Needleman 1970</a></dt>
        <dd>Needleman, Saul B. and Wunsch, Christian D., 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins.
            Journal of Molecular Biology 48 (3), 443–53.</dd>

        <dt id="bib-nmerge-2012"><a href="https://github.com/HRIT-Infrastructure/NMergeNew" title="GitHub">NMerge 2012</a></dt>
        <dd>Schmidt, D., 2012. NMerge. The nmerge Java library/commandline tool for making multi-version documents.</dd>

        <dt id="bib-schmidt-2008"><a href="http://multiversiondocs.blogspot.com/2008/03/whats-multi-version-document.html">Schmidt 2008</a></dt>
        <dd>Schmidt, D., 2008. What's a Multi-Version Document. <a href="http://multiversiondocs.blogspot.com/"title="Web Resource">Multi-Version Documents Blog</a>.</dd>

        <dt id="bib-schmidt-2009"><a href="http://dx.doi.org/10.1016/j.ijhcs.2009.02.001" title="Electronic Article">Schmidt 2009</a></dt>
        <dd>Schmidt, D. and Colomb, R., 2009. A data structure for representing multi-version texts online.
            International Journal of Human-Computer Studies, 67.6, 497-514.</dd>

        <dt id="bib-schmidt-2009a"><a href="http://www.balisage.net/Proceedings/vol3/html/Schmidt01/BalisageVol3-Schmidt01.html">Schmidt 2009a</a></dt>
        <dd>Schmidt, D., 2009. Merging Multi-Version Texts: a Generic Solution to the Overlap Problem.” Presented at Balisage:
            The Markup Conference 2009, Montréal, Canada, August 11 - 14, 2009. In Proceedings of Balisage: The Markup Conference 2009.
            Balisage Series on Markup Technologies, vol. 3 (2009). doi:10.4242/BalisageVol3.Schmidt01.</dd>

        <dt id="bib-spencer-2004"><a href="http://dx.doi.org/10.1007/s10579-004-8682-1">Spencer 2004</a></dt>
        <dd>Spencer M., Howe and Christopher J., 2004. Collating Texts Using Progressive Multiple Alignment. Computers and
            the Humanities. 38/2004, 253–270.</dd>

        <dt id="bib-stolz-2006"><a href="http://edoc.bbaw.de/volltexte/2007/516/">Stolz 2006</a></dt>
        <dd>Stolz, M. and Dimpel F. M., 2006. Computergestützte Kollationierung und ihre Integration in den editorischen
            Arbeitsfluss. 2006.</dd>
    </dl>
{% endblock %}

{% block appendix %}
    {{ parent() }}
    <script type="text/javascript" src="/toc.js"></script>
{% endblock %}